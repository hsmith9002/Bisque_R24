---
title: "snRNA-Seq Analysis Using BNLx/SHR - Default Analysis"
author: "Harry A. Smith"
date: "`R Sys.Date()`"
output:
  html_document:
    toc: true
    toc_float: true
    toc_collapsed: false
    fig_caption: yes
    fig_retina: 1 
    code_folding: hide
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(cache = FALSE)
knitr::opts_chunk$set(warning = FALSE)
knitr::opts_chunk$set(cache.lazy = FALSE)
```


```{r libs, message=FALSE, warning=FALSE, echo=FALSE}
library(Seurat)
library(cowplot)
library(RColorBrewer)
library(Matrix)
library(tidyverse)
library(R.utils)
library(viridis)
library(patchwork)

data_dir <- "/Users/smithh/Documents/Saba_Lab/cellranger_results"
tcols <- rev(brewer.pal(11, "RdGy")[c(1:5, 7)])[1:6]
```

## Experiment Summary

Sample | Description
------------- | ---------------- 
1_BNLx_1_Neurons | BNLx Biological Replicate 1 
3_BNLx_2_Neurons | BNLx Biological Replicate 2
5_SHR_1_Neurons | SHR Biological Replicate 1  
7_SHR_2_Neurons | SHR Biological Replicate 2

```{r in_data}

samples <- c(
  "1_BNLx_1_Neurons",
  "3_BNLx_2_Neurons",
  "5_SHR_1_Neurons",
  "7_SHR_2_Neurons")

sample_paths <- file.path(data_dir ,
                          samples)

names(sample_paths) <- samples

bcells <- Seurat::Read10X(sample_paths)
```

```{r create_seurat, message = F, results = 'hide', warning = F}
bcells <- CreateSeuratObject(counts = bcells, 
                              min.cells = 3,
                              min.genes = 200, 
                              project = "Saba",
                              names.field = c(1,2), 
                              names.delim = "_")
```

```{r additional_mdata}

# add correct sample identifier
ids <- colnames(bcells@assays$RNA@data)
ids <- str_split(ids, "_[ATCG]{10}", simplify = T) %>% .[, 1]
ids <- data.frame(row.names = colnames(bcells@assays$RNA@data),
                  expt = ids)
bcells <- AddMetaData(bcells, ids)
```

  
```{r examine_umi_and_ngenes, fig.width = 10, fig.height = 8, warning = F, eval=FALSE}
summary_dat <- data_frame(cell = colnames(bcells@assays$RNA@data), 
                          expt = bcells@meta.data$expt,
                          nUMIs = colSums(as.matrix(bcells@assays$RNA@data)),
                          nGenes = colSums(as.matrix(bcells@assays$RNA@data) > 0))

summary_dat <- summary_dat %>% 
  group_by(expt) %>% 
  dplyr::arrange(desc(nUMIs))

n_cells <- summary_dat %>%  
  group_by(expt) %>%  
  summarize(n_cells = n(),
            median_UMIs = median(nUMIs),
            median_Genes = median(nGenes))

knitr::kable(n_cells,
             caption = "Number of cells prior to filtering and summary statistics")

a <- ggplot(summary_dat, aes(expt, nUMIs)) +
  geom_violin(aes(fill = expt)) +
  scale_fill_brewer(palette = "Paired") +
  ylab("Number of UMIs (Log10)") +
  theme(axis.text.x = element_blank())

b <- ggplot(summary_dat, aes(expt, nGenes)) +
    geom_violin(aes(fill = expt)) +
  scale_fill_brewer(palette = "Paired") +
  ylab("Number of Genes (at least 1 UMI) Log10") +
  theme(axis.text.x = element_blank())
plot_grid(a, b, ncol = 1)
```



```{r write_matrix, eval = F}
dir.create("/Users/smithh/Documents/Saba_Lab/cellranger_results/count_matrix", showWarnings = FALSE)

write.table(as.matrix(bcells@assays$RNA@data),
            file.path("/Users/smithh/Documents/Saba_Lab/cellranger_results/count_matrix", "all_samples_raw_counts_matrix.txt"),
            quote = F, sep = "\t")

gzip(file.path("/Users/smithh/Documents/Saba_Lab/cellranger_results/count_matrix",
               "all_samples_raw_counts_matrix.txt"),
     overwrite = TRUE,
     remove = TRUE)
```

```{r utility_fxn}
cell_counts <- function(seurat_object){
  #returns tbl_df with number of cells per sample type in seurat object
  map_df(levels(seurat_object@ident), 
         ~data_frame(sample = .x, 
                     n_cells = length(WhichCells(seurat_object, ident = .x))))
}
```

## Raw data {.tabset .tabset-fade}


```{r QC}
# there are not unique IDs for mito genes in refseq, so I  am using this gene list

mito_gene_list <- c("ATP6", "ATP8", "COX1", "COX2", "COX3", "CYTB", "ND1", "ND2", "ND3", "ND4", "ND4L", "ND5", "ND6")
mito_gene_list <- paste0(mito_gene_list, collapse = "|")

mito.genes <- grep(mito_gene_list, rownames(bcells@assays$RNA@data), value = T)
`%!in%` <- Negate(`%in%`)
# Remove mitochondrial genes from analysis
counts <- GetAssayData(bcells, assay = "RNA")
mito.gene.index <- as.numeric(which(rownames(counts) %in% mito.genes))
counts <- counts[-mito.gene.index,]
bcells <- subset(bcells, features = rownames(counts))

# proportion.mito <- Matrix::colSums(bcells@assays$RNA@data[mito.genes, ]) /
#   Matrix::colSums(bcells@assays$RNA@data)
# 
# bcells <- AddMetaData(bcells, proportion.mito, "proportion.mito")
# 
bcells[["percent.mt"]] <- PercentageFeatureSet(bcells, pattern = mito_gene_list)
# 
# unfiltered <- bcells@meta.data %>%
#   tibble::rownames_to_column("cell") %>%
#   left_join(summary_dat, by = c("cell", "expt")) %>%
#   as_data_frame()
# 
# ggplot(unfiltered, aes(expt,
#                        proportion.mito)) +
#   geom_jitter(size = 0.25) +
#   geom_violin(aes(fill = expt), alpha = 0.66) +
#   scale_fill_brewer(palette = "Paired") +
#   theme(
#     axis.text.x = element_text(angle = 90, hjust = 1),
#     axis.title.x = element_blank()
#   )
```

### All Samples

```{r sample_ids}
# ggplot(unfiltered,
#        aes(nUMI, proportion.mito)) +
#   geom_point(aes(color = expt)) +
#   scale_color_brewer(palette = "Paired")
```

```{r, results ='asis'}

sample_names <- as.character(unique(bcells@meta.data$expt))
# per_sample <- map(sample_names, ~filter(unfiltered,
# expt == .x))
# 
# # generate tab with individual plot programmatically
# # see https://stackoverflow.com/questions/43752095/programmatically-insert-header-and-plot-in-same-code-chunk-with-r-markdown-using?noredirect=1&lq=1
# 
# for(i in seq_along(per_sample)){
#   .col <- brewer.pal(10, "Paired")[i]
#   cat('\n### ', sample_names[i], '\n')
#   p <- ggplot(per_sample[[i]], aes(nUMIs, proportion.mito)) +
#         geom_point(aes(color = expt)) +
#         scale_color_manual(values = .col)
#   print(p)
#   cat('\n')
# }

# Visualize QC metrics as a violin plot

VlnPlot(bcells, features = c("nFeature_RNA", "nCount_RNA"), ncol = 2, split.by = 'expt')

```

Cells with low UMIs tend to have a higher percentage of mitochondrial reads, suggesting that these cells have lysed prematurely. However, overall a large proportion of cells are retained for further analysis after removing cells with > 20% UMIs derived from mitochondrial transcripts. In this analysis, however, I did not remove any cells based on mitochondrial content. I did, however, remove the mitochondrial genes from the analysis.

## Filtered Data {.tabset .tabset-fade}

After filtering the distribution of UMIs, Genes, and Proportion of mitochondrial reads are shown as selectable tabs. 

```{r, apply_filters}
bcells <- subset(bcells, subset = nFeature_RNA > 250 & nFeature_RNA < 2500)

```

```{r ngenes_filter}
# knitr::kable(cell_counts(SetAllIdent(bcells, "expt")),
#              caption = "Number of cells passing an additional filter requiring less than 20% mitochondrial reads and at least 250 genes detected, and UMI < 2500")
```

### Post filtering violin plots
```{r ngenes_post_filter}

VlnPlot(bcells, features = c("nFeature_RNA", "nCount_RNA", "percent.mt"), ncol = 3, 
        cols = brewer.pal(10, "Paired"),
        split.by = "expt")

```

## Preprocess the data for PCA, TSNE, and Clustering 
  The raw UMI count matrix will next be preprocessed for downstream clustering and visualization
  
### Normalize the data
  First the UMI count data will be normalized. LogNormalize: Feature counts for each cell are divided by the total counts for that cell and multiplied by the scale.factor. This is then natural-log transformed using log1p.

```{r normalize, results = 'hide'}

bcells <- NormalizeData(bcells, normalization.method = "LogNormalize", scale.factor = 10000)

#library(scran)

# sce <- SingleCellExperiment(list(counts = bcells@raw.data[rownames(bcells@data),
#                                                           rownames(bcells@meta.data)]))
# 
# qclusters <- quickCluster(counts(sce), method = "igraph", min.size = 50)
# sce <- computeSumFactors(sce, 
#                          sizes = seq(20, 100, 5),
#                          cluster = qclusters, 
#                          min.mean = 0.1)
# 
# # return normalize non-log values (log2 is default for scran, log for seurat)
# sce <- scater::normalize(sce, 
#                          return_log = F, 
#                          log_exprs_offset = 0)    
# # add pseudocount of 1 consistent with seurat
# bcells@data <- assay(sce, "normcounts") %>% 
#   log1p(.) %>% 
#   as(., "sparseMatrix")
# 
# # all seurat calc paramters are stored and occasionally checked
# # add normalization method to avoid warnings
# bcells@calc.params[["NormalizeData"]] <- list(normalization.method = "scran::computeSumFactors")

```

### Identify variable genes

  The normalized UMI count matrix contains `r  length(rownames(bcells@assays$RNA@data))` genes and `r length(colnames(bcells@assays$RNA@data))` cells. Most of these genes have very low expression or very low variance across all of the cells in the dataset. These genes are therefore very uninformative for classifying different cell types. In this next step the set of variable genes useful for classification will be identified, and used for downstream PCA, TSNE, and classification purposes. 
  
  Variable genes will be selected by examining a plot of the average expression across all cells on the x axis to the dispersion across all genes. Highly variable genes will have non-zero dispersion. The dispersion is defined by the variance / mean. 
  
```{r get_variable_genes, results = 'hide'}
# bcells <- FindVariableFeatures(bcells, 
#                     mean.function = ExpMean, 
#                     dispersion.function = LogVMR, 
#                     x.low.cutoff = 0.1, 
#                     x.high.cutoff = 5, 
#                     y.cutoff = 0.4, do.contour = F, do.plot = T)

bcells <- FindVariableFeatures(
  bcells,
  selection.method = "vst",
  verbose = TRUE)

# Identify the 10 most highly variable genes
top10 <- head(VariableFeatures(bcells), 10)

# plot variable features with and without labels
plot1 <- VariableFeaturePlot(bcells)
plot2 <- LabelPoints(plot = plot1, points = top10, repel = TRUE, xnudge = 0, ynudge = 0)
plot2
```

### Control for noise
  Single-cell data is often noisy, and it is difficult to compare cells with very high UMIs to very low UMIs. For classification we do not want to bias our clusters based on nuisance variables such as UMI count or proportion of mitochondria. To help mitigate bias in our clustering a regression model is fit to predict gene expression based on nuisance variables. The residuals from this fit are then scaled and centered (i.e. turned into z-scores) for classification purposes. The scaled regressed data is not used for differential expression, but used only for classifcation, TSNE visualization, and pseudotime analysis. 
  
From function description: Scales and centers features in the dataset. If variables are provided in vars.to.regress, they are individually regressed against each feature, and the resulting residuals are then scaled and centered.

```{r scale_data, results='hide', message = F}
all.genes <- rownames(bcells)
bcells <- ScaleData(bcells, features = all.genes, split.by = 'expt')
```

### Calculate Principal Components

  PCA will now be performed on processed data using only the set of variable genes defined above. PCA will generate a set of new vectors that describe the variablity in the data. A subset of these principal components will be selected to be used as input data for TSNE visualization. Selecting the proper number of components is informed by examining the amount of variance captured in each PC. Shown below is a plot of variance captured in each PC. At a certain point, additional PCs capture little additional varaince, and therefore are uninformative for classification. For this dataset 20 PCs will be used for classification.
  
```{r PCA_calc, results='hide'}
bcells <- RunPCA(bcells, features = VariableFeatures(object = bcells))

VizDimLoadings(bcells, dims = 1:2, reduction = "pca")

DimPlot(bcells, reduction = "pca")
DimPlot(bcells, reduction = "pca", split.by = 'expt')

# PCElbowPlot(bcells)
```

### PCA Heatmaps {.tabset .tabsetfade}
  
  
```{r pc_plots, results ='asis'}
DimHeatmap(bcells, dims = 1:15, cells = 500, balanced = TRUE)


# for(i in seq_along(pcs)){
#   cat('\n#### ', 'PC', pcs[[i]][1], ' vs PC', pcs[[i]][2], '\n', sep = "")
#   DimPlot(bcells,
#               dims =  c(pcs[[i]][1],
#                pcs[[i]][2]),
#                col = brewer.pal(10, "Paired"),
#         group.by = "expt")
#   #print(p)
#   cat('\n')
# }
```

### Determining dimensionality of the data {.tabset .tabset-fade}

To overcome the extensive technical noise in any single feature for scRNA-seq data, Seurat clusters cells based on their PCA scores, with each PC essentially representing a ‘metafeature’ that combines information across a correlated feature set. The top principal components therefore represent a robust compression of the dataset. However, how many components should we choose to include? 10? 20? 100?

In Macosko et al, we implemented a resampling test inspired by the JackStraw procedure. We randomly permute a subset of the data (1% by default) and rerun PCA, constructing a ‘null distribution’ of feature scores, and repeat this procedure. We identify ‘significant’ PCs as those who have a strong enrichment of low p-value features.

```{r, dim_determine, results ='asis'}
bcells <- JackStraw(bcells, num.replicate = 100)
bcells <- ScoreJackStraw(bcells, dims = 1:20)
```

#### JackStraw Plot

The JackStrawPlot() function provides a visualization tool for comparing the distribution of p-values for each PC with a uniform distribution (dashed line). ‘Significant’ PCs will show a strong enrichment of features with low p-values (solid curve above the dashed line). In this case it appears that there is a sharp drop-off in significance after the first 15-20 PCs.

```{r js_plot, results ='asis'}
JackStrawPlot(bcells, dims = 1:20)
```

#### Elbow Plot

An alternative heuristic method generates an ‘Elbow plot’: a ranking of principle components based on the percentage of variance explained by each one (ElbowPlot() function). In this example, we can observe an ‘elbow’ around PC 15, suggesting that the majority of true signal is captured in the first 15 PCs.

```{r elbow_plot, results ='asis'}
ElbowPlot(bcells)
```

### Cluster cells {.tabset .tabsetfade}

Seurat v3 applies a graph-based clustering approach, building upon initial strategies in (Macosko et al). Importantly, the distance metric which drives the clustering analysis (based on previously identified PCs) remains the same. However, our approach to partitioning the cellular distance matrix into clusters has dramatically improved. Our approach was heavily inspired by recent manuscripts which applied graph-based clustering approaches to scRNA-seq data [SNN-Cliq, Xu and Su, Bioinformatics, 2015] and CyTOF data [PhenoGraph, Levine et al., Cell, 2015]. Briefly, these methods embed cells in a graph structure - for example a K-nearest neighbor (KNN) graph, with edges drawn between cells with similar feature expression patterns, and then attempt to partition this graph into highly interconnected ‘quasi-cliques’ or ‘communities’.

As in PhenoGraph, we first construct a KNN graph based on the euclidean distance in PCA space, and refine the edge weights between any two cells based on the shared overlap in their local neighborhoods (Jaccard similarity). This step is performed using the FindNeighbors() function, and takes as input the previously defined dimensionality of the dataset (first 10 PCs).

To cluster the cells, we next apply modularity optimization techniques such as the Louvain algorithm (default) or SLM [SLM, Blondel et al., Journal of Statistical Mechanics], to iteratively group cells together, with the goal of optimizing the standard modularity function. The FindClusters() function implements this procedure, and contains a resolution parameter that sets the ‘granularity’ of the downstream clustering, with increased values leading to a greater number of clusters. We find that setting this parameter between 0.4-1.2 typically returns good results for single-cell datasets of around 3K cells. Optimal resolution often increases for larger datasets. The clusters can be found using the Idents() function.
  
    
```{r select_dims}
bcells <- FindNeighbors(bcells, dims = 1:20)
bcells <- FindClusters(bcells, resolution = 0.5)

# reticulate::py_install(packages =
#  'umap-learn')
```

Seurat offers several non-linear dimensional reduction techniques, such as tSNE and UMAP, to visualize and explore these datasets. The goal of these algorithms is to learn the underlying manifold of the data in order to place similar cells together in low-dimensional space. Cells within the graph-based clusters determined above should co-localize on these dimension reduction plots. As input to the UMAP and tSNE, we suggest using the same PCs as input to the clustering analysis.

```{r run_UMAP, results='asis'}
bcells <- RunUMAP(bcells, dims = 1:20)

DimPlot(bcells, reduction = "umap")

DimPlot(bcells, reduction = "umap", split.by = 'expt', ncol = 2)
```

```{r saveRDS, eval=FALSE}
# save Seurat Object
saveRDS(bcells, file = paste0(data_dir, "/", "bcells_default.rds"))
```

## get cell proportions by cluster

```{r cell_prop, eval=FALSE}
readRDS(file = paste0(data_dir, "/", "bcells_default.rds"))

cell_prop_by_sample <- prop.table(table(bcells@meta.data$expt, Idents(bcells)))

write.csv(cell_prop_by_sample, file = paste0(data_dir, "/", "bcells_default_cellprop_bysample.csv"))
```

## UMAP with down sampled data set

```{r down_sample}
# get number of cells in one of the lower samples
cells.to.sample <- (bcells@meta.data) %>%
  filter(expt == '5_SHR_1_Neurons') %>%
  nrow()

# get vectors of cell ids for the other 3 samples except 7_SHR_2_Neurons because it doesn't have enough
BNLx_1_Neurons.cellvect <- (bcells@meta.data) %>%
  filter(expt == '1_BNLx_1_Neurons') %>%
  rownames()
BNLx_2_Neurons.cellvect <- (bcells@meta.data) %>%
  filter(expt == '3_BNLx_2_Neurons') %>%
  rownames()
SHR_1_Neurons.cellvect <- (bcells@meta.data) %>%
  filter(expt == '5_SHR_1_Neurons') %>%
  rownames()
SHR_2_Neurons.cellvect <- (bcells@meta.data) %>%
  filter(expt == '7_SHR_2_Neurons') %>%
  rownames()

# Sample from bcells as many cells as there are cells in cells.to.sample
# For reproducibility, set a random seed
set.seed(1020)
BNLx_1_Neurons.sampled.cells <- sample(x = BNLx_1_Neurons.cellvect, size = cells.to.sample, replace = F)
BNLx_2_Neurons.sampled.cells <- sample(x = BNLx_2_Neurons.cellvect, size = cells.to.sample, replace = F)

# concat sampled cell names for indexing bcells
sampled.cells <- c(BNLx_1_Neurons.sampled.cells, 
                   BNLx_2_Neurons.sampled.cells,
                   SHR_1_Neurons.cellvect,
                   SHR_2_Neurons.cellvect)

# Subset Seurat object
bcells.sub <- subset(x=bcells, cells = sampled.cells)

# regenerate UMAPs with down sampled data
bcells.sub <- RunUMAP(bcells.sub, dims = 1:20)

DimPlot(bcells.sub, reduction = "umap")

DimPlot(bcells.sub, reduction = "umap", split.by = 'expt')
```

```{r cell_prp_downsample}
cell_prop_by_sample_down_sample <- prop.table(table(bcells.sub@meta.data$expt, Idents(bcells.sub)))

write.csv(cell_prop_by_sample_down_sample, file = paste0(data_dir, "/", "bcells_sub_default_cellprop_bysample.csv"))



```


## Differential Expression and Marker Gene Identification

Seurat can help you find markers that define clusters via differential expression. By default, it identifies positive and negative markers of a single cluster (specified in ident.1), compared to all other cells. FindAllMarkers() automates this process for all clusters, but you can also test groups of clusters vs. each other, or against all cells.

The min.pct argument requires a feature to be detected at a minimum percentage in either of the two groups of cells, and the thresh.test argument requires a feature to be differentially expressed (on average) by some amount between the two groups. You can set both of these to 0, but with a dramatic increase in time - since this will test a large number of features that are unlikely to be highly discriminatory. As another option to speed up these computations, max.cells.per.ident can be set. This will downsample each identity class to have no more cells than whatever this is set to. While there is generally going to be a loss in power, the speed increases can be significant and the most highly differentially expressed features will likely still rise to the top.

```{r find_markers, eval=FALSE}
# find markers for every cluster compared to all remaining cells, report only the positive
# ones
bcells.markers <- FindAllMarkers(bcells, only.pos = TRUE, min.pct = 0.25, logfc.threshold = 0.25)
bcells.markers %>%
    group_by(cluster) %>%
    slice_max(n = 2, order_by = avg_log2FC)

write_csv(bcells.markers, file = paste0(data_dir, "/", "all_markers_all_clusters.csv"))
```

## CelliD Analaysis

```{r cell_prop, eval=FALSE}
library(CelliD)

readRDS(file = paste0(data_dir, "/", "bcells_default.rds"))

##################################################################
# Obtaining pancreatic cell-type gene signatures
##################################################################

# download all cell-type gene signatures from panglaoDB
panglao <- read_tsv("https://panglaodb.se/markers/PanglaoDB_markers_27_Mar_2020.tsv.gz")

# restricting the analysis to pancreas specific gene signatues
panglao_brain <- panglao %>% filter(organ == "Brain")

# restricting to human specific genes
panglao_brain <- panglao_brain %>%  filter(str_detect(species,"Mm"))

# converting dataframes into a list of vectors, which is the format needed as input for CelliD
panglao_brain <- panglao_brain %>%  
  group_by(`cell type`) %>%  
  summarise(geneset = list(`official gene symbol`))
brain_gs <- setNames(panglao_brain$geneset, panglao_brain$`cell type`)

##################################################################
# Obtaining gene signatures for all cell types in the Panglao database
##################################################################

#filter to get human specific genes
panglao_all <- panglao %>%  filter(str_detect(species,"Mm"))

# convert dataframes to a list of named vectors which is the format for CelliD input
panglao_all <- panglao_all %>%  
  group_by(`cell type`) %>%  
  summarise(geneset = list(`official gene symbol`))
all_gs <- setNames(panglao_all$geneset, panglao_all$`cell type`)

#remove very short signatures
all_gs <- all_gs[sapply(all_gs, length) >= 10]

```

## Session Info
```{r ses}
sessionInfo()
```