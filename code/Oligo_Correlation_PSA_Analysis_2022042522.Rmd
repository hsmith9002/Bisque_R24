---
title: "Oligos Correlation and PSA Ananlysis"
author: "Harry Smith"
date: "R Sys.Date()"
output:
  html_document:
    toc: true
    toc_float: true
    toc_collapsed: false
    fig_caption: yes
    fig_retina: 1 
    code_folding: hide
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(cache = FALSE)
knitr::opts_chunk$set(warning = FALSE)
knitr::opts_chunk$set(cache.lazy = FALSE)
```


```{r libs, message=FALSE, warning=FALSE, echo=FALSE}
library(tidyverse)
library(data.table)
library(Seurat)
library(scater)
library(cowplot)
library(RColorBrewer)
library(Matrix)
library(tidyverse)
library(R.utils)
library(viridis)
library(patchwork)
library(Matrix.utils)
library(magrittr)
library(CelliD)
library(muscat)
library(purrr)

data_dir <- "/Users/smithh/Documents/Saba_Lab/cellranger_results"
tcols <- rev(brewer.pal(11, "RdGy")[c(1:5, 7)])[1:6]
```

## Experiment Summary

Sample | Description
------------- | ---------------- 
4_BNLx_2_Oligos | BNLx Biological Replicate 1 
6_SHR_1_Oligos | SHR Biological Replicate 1
8_SHR_2_Oligos | SHR Biological Replicate 2  

```{r import data}
# import oligo data sets
oligos <- readRDS(file = paste0(data_dir, "/", "oligos_default.rds"))

# sub cluster seurat object
oligos_sub <- readRDS(file = paste0(data_dir, "/", "oligos_subcluster.rds"))

```

```{r pseudo_counts}
library(purrr)
#########################################
# prep seurat object
#########################################

# Extract raw counts and metadata to create SingleCellExperiment object
counts <- oligos@assays$RNA@counts 

metadata <- oligos@meta.data

# Set up metadata as desired for aggregation and DE analysis
metadata$seurat_clusters <- factor(oligos@active.ident)

# Create single cell experiment object
sce <- SingleCellExperiment(assays = list(counts = counts), 
                           colData = metadata)

# Identify groups for aggregation of counts
groups <- colData(sce)[, c("seurat_clusters", "expt")]


# Named vector of cluster names
kids <- purrr::set_names(levels(sce$seurat_clusters))
kids

# Total number of clusters
nk <- length(kids)
nk

# Named vector of sample names
sids <- purrr::set_names(levels(sce$expt))

# Total number of samples 
ns <- length(sids)
ns

##################################
# Generate sample level metadata
##################################

## Determine the number of cells per sample
table(sce$expt)

## Turn named vector into a numeric vector of number of cells per sample
n_cells <- as.numeric(table(sce$expt))

## Determine how to reoder the samples (rows) of the metadata to match the order of sample names in sids vector
m <- match(sids, sce$expt)

## Create the sample level metadata by combining the reordered metadata with the number of cells corresponding to each sample.
ei <- data.frame(colData(sce)[m, ], 
                  n_cells, row.names = NULL) %>% 
                select(-"seurat_clusters")
ei

#####################################################
# Aggregate the counts per sample_id and cluster_id
#####################################################

# Subset metadata to only include the cluster and sample IDs to aggregate across
groups <- colData(sce)[, c("seurat_clusters", "expt")]

# Aggregate across cluster-sample groups
pb <- aggregate.Matrix(t(counts(sce)), 
                       groupings = groups, fun = "sum") 

class(pb)

dim(pb)

pb[1:6, 1:6]

# Not every cluster is present in all samples; create a vector that represents how to split samples
splitf <- sapply(stringr::str_split(rownames(pb), 
                                    pattern = "_",  
                                    n = 2), 
                 `[`, 1)

# Turn into a list and split the list into components for each cluster and transform, so rows are genes and columns are samples and make rownames as the sample IDs
pb <- split.data.frame(pb, 
                       factor(splitf)) %>%
        lapply(function(u) 
                set_colnames(t(u), 
                             stringr::str_extract(rownames(u), "(?<=_)[:alnum:]+")))

class(pb)

# Explore the different components of list
str(pb)

# Print out the table of cells in each cluster-sample group
options(width = 100)
table(sce$seurat_clusters, sce$expt)
```

## Gene Correlation Analysis

```{r gene_correlation}
library(qlcMatrix)
# Calculate spearman correlations on all genes by cluster
test <- as.data.frame(pb$`0`)
test <- data.table(test)
test_t <- as.data.frame(t(test))
colnames(test_t) <- rownames(pb$`0`)

# get vector of variable genes
vargenes <- VariableFeatures(oligos_sub)

#subset test_t to only inlcude variable genes
test_t <- test_t[, which(colnames(test_t) %in% vargenes)]

cor_res <- as.data.frame(corSparse(test_t))

colnames(cor_res) <- colnames(test_t)
rownames(cor_res) <- colnames(test_t)

res <- cor_res %>% as.data.frame %>% tibble::rownames_to_column() %>% 
    tidyr::pivot_longer(-rowname)

```

## Psuedo Bulk using Muscat

```{r, muscat}
library(muscat)

# clean up sample names
sce$expt <- gsub('4', 'BN', sce$expt)
sce$expt <- gsub('6', 'SHR1', sce$expt)
sce$expt <- gsub('8', 'SHR2', sce$expt)

##################################
# sce QC
##################################

# remove undetected genes
sce <- sce[rowSums(counts(sce) > 0) > 0, ]
dim(sce)

qc <- perCellQCMetrics(sce)

# remove cells with few or many detected genes
ol <- isOutlier(metric = qc$detected, nmads = 2, log = TRUE)
sce <- sce[, !ol]
dim(sce)

#remove lowly expressed genes
sce <- sce[rowSums(counts(sce) > 1) >= 10, ]
dim(sce)

# compute sum-factors & normalize
sce <- computeLibraryFactors(sce)
sce <- logNormCounts(sce)

##########################################
# Prep SCE object for down stream analysis
##########################################

sce$id <- paste0(sce$expt, sce$seurat_clusters)
(sce <- prepSCE(sce, 
    kid = "seurat_clusters", # subpopulation assignments
    gid = "expt",  # group IDs (ctrl/stim)
    sid = "id",   # sample IDs (ctrl/stim.1234)
    drop = TRUE))  # drop all other colData columns

##################################
# Generate sample level metadata
##################################

## Determine the number of cells per sample
table(sce$sample_id)

## Turn named vector into a numeric vector of number of cells per sample
n_cells <- as.numeric(table(sce$sample_id))

## Determine how to reoder the samples (rows) of the metadata to match the order of sample names in sids vector
m <- match(sids, sce$sample_id)

## Create the sample level metadata by combining the reordered metadata with the number of cells corresponding to each sample.
# ei <- data.frame(colData(sce)[m, ], 
#                   n_cells, row.names = NULL) %>% 
#                 select(-"seurat_clusters")
# ei

#####################################################
# Dimension Reduction and Plotting
#####################################################

# # compute UMAP using 1st 20 PCs
# sce <- runUMAP(sce, pca = 20)
# 
# # wrapper to prettify reduced dimension plots
# .plot_dr <- function(sce, dr, col)
#   plotReducedDim(sce, dimred = dr, colour_by = col) +
#     guides(fill = guide_legend(override.aes = list(alpha = 1, size = 3))) +
#     theme_minimal() + theme(aspect.ratio = 1)
# 
# # downsample to max. 100 cells per cluster
# cs_by_k <- split(colnames(sce), sce$cluster_id)
# cs100 <- unlist(sapply(cs_by_k, function(u) 
#   sample(u, min(length(u), 100))))
# 
# # plot t-SNE & UMAP colored by cluster & group ID
# for (dr in c("TSNE", "UMAP"))
#   for (col in c("seurat_clusters", "expt"))
#     .plot_dr(sce[, cs100], dr, col)

#####################################################
# Aggregate the counts per sample_id and cluster_id
#####################################################

# Subset metadata to only include the cluster and sample IDs to aggregate across
groups <- colData(sce)[, c("cluster_id", "sample_id")]

# pb_mus_byCluster <- aggregateData(sce,
#     assay = "counts", fun = "sum",
#     by = c("cluster_id"))
# head(assay(pb_mus_byCluster))

pb_mus <- aggregateData(sce,
    assay = "logcounts", fun = "mean",
    by = c("sample_id"))
head(assay(pb_mus))

pb_mus_cnts <- aggregateData(sce,
    assay = "counts", fun = "sum",
    by = c("sample_id"))


#####################################################
# Sample level DS Ananlysis
#####################################################



# # run DS analysis
# res <- pbDS(pb_mus, verbose = TRUE)
# # access results table for 1st comparison
# tbl <- res$table[[1]]
# 
# # view results for 1st cluster
# k1 <- tbl[[1]]
# head(format(k1[, -ncol(k1)], digits = 2))
```

## Correlation analysis - muscat data

```{r, cor_muscat}
library(qlcMatrix)

pc_matrix <- as.data.frame(assay((pb_mus)))

cnt_matrix <- as.data.frame(assay(pb_mus_cnts))

# build data frames by cluster
cluster0pc <- as.data.frame(cbind(pc_matrix$BN_BNLx0, pc_matrix$SHR1_SHR0, pc_matrix$SHR2_SHR0))
colnames(cluster0pc) <- c("BNLx", "SHR1", "SHR2")
rownames(cluster0pc) <- rownames(pc_matrix)

cluster1pc <- as.data.frame(cbind(pc_matrix$BN_BNLx1, pc_matrix$SHR1_SHR1, pc_matrix$SHR2_SHR1))
colnames(cluster0pc) <- c("BNLx", "SHR1", "SHR2")
rownames(cluster0pc) <- rownames(pc_matrix)

cluster2pc <- as.data.frame(cbind(pc_matrix$BN_BNLx2, pc_matrix$SHR1_SHR2, pc_matrix$SHR2_SHR2))
colnames(cluster0pc) <- c("BNLx", "SHR1", "SHR2")
rownames(cluster0pc) <- rownames(pc_matrix)

cluster3pc <- as.data.frame(cbind(pc_matrix$BN_BNLx3, pc_matrix$SHR1_SHR3, pc_matrix$SHR2_SHR3))
colnames(cluster0pc) <- c("BNLx", "SHR1", "SHR2")
rownames(cluster0pc) <- rownames(pc_matrix)

cluster4pc <- as.data.frame(cbind(pc_matrix$BN_BNLx4, pc_matrix$SHR1_SHR4, pc_matrix$SHR2_SHR4))
colnames(cluster0pc) <- c("BNLx", "SHR1", "SHR2")
rownames(cluster0pc) <- rownames(pc_matrix)

cluster5pc <- as.data.frame(cbind(pc_matrix$BN_BNLx5, pc_matrix$SHR1_SHR5, pc_matrix$SHR2_SHR5))
colnames(cluster0pc) <- c("BNLx", "SHR1", "SHR2")
rownames(cluster0pc) <- rownames(pc_matrix)

cluster6pc <- as.data.frame(cbind(pc_matrix$BN_BNLx6, pc_matrix$SHR1_SHR6, pc_matrix$SHR2_SHR6))
colnames(cluster0pc) <- c("BNLx", "SHR1", "SHR2")
rownames(cluster0pc) <- rownames(pc_matrix)

cor_fun <- function(x){
  # calc correlation
  cor_res <- as.data.frame(cor(t(x), method = 'pearson'))
  # make pretty
  res <- cor_res %>% as.data.frame %>% tibble::rownames_to_column() %>% 
    tidyr::pivot_longer(-rowname)
  # remove rows where gene is correlated with itself
  clean <- subset(res, res$rowname != res$name)
  # Identify top 100 most correlated genes
  out <- clean %>%
    group_by(rowname) %>%
    arrange(desc(value)) %>%
    dplyr::slice(1:10)
  #caclulate average correlations
  cor_avg <- out %>%
    group_by(rowname) %>%
    summarize(mean_cor = mean(value, na.rm = TRUE))
  mean_all <- mean(cor_avg$mean_cor, na.rm = TRUE)
  list_out <- list("rawResults" = out, "CorAvgs" = cor_avg, "OverallAgv" = mean_all )
  return(list_out)
}

c1_cor <- cor_fun(cluster0pc)

# Identify Out of 5K genes, how many have more than 5 read in all samples in at least 1 cluster

# check to see if gene has > 5 reads for each sample and cluster
ch1_out <- list()
for(i in seq_along(colnames(cnt_matrix))){
  check1 <- ifelse(cnt_matrix[, i] > 5, 1, 0)
  ch1_out[[i]] <- check1
}

# add above results to cnt_matrix
cnt_matrix$BN_BNLx0_ch1 <- ch1_out[[1]]
cnt_matrix$BN_BNLx1_ch1 <- ch1_out[[2]]
cnt_matrix$BN_BNLx2_ch1 <- ch1_out[[3]]
cnt_matrix$BN_BNLx3_ch1 <- ch1_out[[4]]
cnt_matrix$BN_BNLx4_ch1 <- ch1_out[[5]]
cnt_matrix$BN_BNLx5_ch1 <- ch1_out[[6]]
cnt_matrix$BN_BNLx6_ch1 <- ch1_out[[7]]
cnt_matrix$SHR1_SHR0_ch1 <- ch1_out[[8]]
cnt_matrix$SHR1_SHR1_ch1 <- ch1_out[[9]]
cnt_matrix$SHR1_SHR2_ch1 <- ch1_out[[10]]
cnt_matrix$SHR1_SHR3_ch1 <- ch1_out[[11]]
cnt_matrix$SHR1_SHR4_ch1 <- ch1_out[[12]]
cnt_matrix$SHR1_SHR5_ch1 <- ch1_out[[13]]
cnt_matrix$SHR1_SHR6_ch1 <- ch1_out[[14]]
cnt_matrix$SHR2_SHR0_ch1 <- ch1_out[[15]]
cnt_matrix$SHR2_SHR1_ch1 <- ch1_out[[16]]
cnt_matrix$SHR2_SHR2_ch1 <- ch1_out[[17]]
cnt_matrix$SHR2_SHR3_ch1 <- ch1_out[[18]]
cnt_matrix$SHR2_SHR4_ch1 <- ch1_out[[19]]
cnt_matrix$SHR2_SHR5_ch1 <- ch1_out[[20]]
cnt_matrix$SHR2_SHR6_ch1 <- ch1_out[[21]]

# create a df of ch1 results for each sample - If there is a 1, that means that gene had > 5 reads in that sample_cluster combo
ch1_df <- cnt_matrix[, 22:42]
ch1_bn1 <- ch1_df[, 1:7]
ch1_shr1 <- ch1_df[, 8:14]
ch1_shr2 <- ch1_df[, 15:21]

# sum each row to. If sum is > 1 then 1 else 0 - the reason for doing this is that if the sum is > 1, then that means that gene has > 5 reads in at least one cluster for that given sample
bn_sum <- apply(ch1_bn1, 1, sum)
shr1_sum <- apply(ch1_shr1, 1, sum)
shr2_sum <- apply(ch1_shr2, 1, sum)

# add sum results back to ch1 df
ch1_df$bn_sum <- bn_sum
ch1_df$shr1_sum <- shr1_sum
ch1_df$shr2_sum <- shr2_sum

# extract sum results as df. The reason for this is to keep the gene names
check_sum_df <- ch1_df[, 22:24]

# check to see if number for each sample is > 0. If it is that means that gene has > 5 read counts in at least 1 cluster in all 3 samples. Change this data frame from numbers to TRUE/FALSE
check_sum_df$bn_logic <- ifelse(check_sum_df$bn_sum > 0, TRUE, FALSE)
check_sum_df$shr1_logic <- ifelse(check_sum_df$shr1_sum > 0, TRUE, FALSE)
check_sum_df$shr2_logic <- ifelse(check_sum_df$shr2_sum > 0, TRUE, FALSE)

# Extract logic results into a df
check_logic_df <- check_sum_df[, 4:6]

# create a vector that if the sum of each row/gene is > 0 then TRUE, else FALSE. This vectore can then be summed to let us know how many genes have > 5 reads in all samples in at least one sample, and can also be used to index the gene list or original count matrix.

final_check_sum <- apply(check_logic_df, 1, sum)
final_check_index <- ifelse(final_check_sum == 3, TRUE, FALSE)
sum(final_check_index)
sum(final_check_index)/length(final_check_index)

```

## PCA Analysis

```{r pca}
library(stringi)
library(ggfortify)
oli_pca <- prcomp(pc_matrix)
oli_pca_df <- as.data.frame(oli_pca$rotation)
oli_pca_df$Strain1 <- sapply(strsplit(rownames(oli_pca_df),"_"), `[`, 1)
oli_pca_df$Cluster <- stri_sub(rownames(oli_pca_df), -1)
oli_pca_df$Strain <- c(rep("BNLx", 7), rep("SHR", 14))


p <- ggplot(data = oli_pca_df, aes(x = PC1, y = PC2, color = Cluster, shape = Strain, size = 2)) +
  geom_point(alpha = 5.0) + xlab("PC1 (72%)") + ylab("PC2 (14%)") +theme_classic()
ggsave(p, filename = "oligo_nn_PCAPlot", device = "pdf", path = data_dir)


######################################
# Calculate PC  ratios
######################################

# Build ratio calculater function
pca_ratio <- function(df, clN, PC){
  # build indexes to extract desired values
  index.shr1 <- rownames(df) == paste0("SHR1_SHR", clN)
  index.shr2 <- rownames(df) == paste0("SHR2_SHR", clN)
  index.bn <- rownames(df) == paste0("BN_BNLx", clN)
  
  # calculate pca1_shr_clusterN
  pca1_shr_clusterN <- min(abs((df[index.shr1,PC] - df[index.bn,PC])),
                           abs((df[index.shr2,PC] - df[index.bn,PC])))
  
  # calculate ratio
  ratio <- (abs((df[index.shr1,PC] - df[index.shr2,PC]))) / 
           (abs((pca1_shr_clusterN - df[index.bn,PC])))
  return(ratio)
}

# calculate pca ratios
cluster <- c(0:6)
pca1_ratio_vec <- c()
for(i in 1:7){
  a <- pca_ratio(oli_pca_df, cluster[i], 1)
  pca1_ratio_vec[i] <- a
}
pca2_ratio_vec <- c()
for(i in 1:7){
  a <- pca_ratio(oli_pca_df, cluster[i], 2)
  pca2_ratio_vec[i] <- a
}
  
# build data frame for plotting
ratio_df <- as.data.frame(cbind(pca1_ratio_vec, pca2_ratio_vec))
colnames(ratio_df) <- c("PC_1", "PC_2")
ratio_df$Cluster <- c(paste0(rep("C_", 7), 0:6))

ratio_df <- data.frame("Cluster" = rep(c(paste0(rep("C_", 7), 0:6)),2), 
                       "Ratio" = c(pca1_ratio_vec, pca2_ratio_vec),
                       "PC" = as.factor(c(rep("P_C1", 7), rep("PC_2", 7))))

ratio_plot <- ggplot(ratio_df) + 
  geom_point(aes(Ratio, Cluster, color = PC, shape = PC, size = 3)) + 
  theme_classic() +
  xlab("Ratio") + ylab("Cluster")

ggsave(ratio_plot, filename = "oligo_PC_Ratio_Plot", device = "pdf", path = data_dir)
```

## Differential Expression

```{r DE_analysis}


```